{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c51af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import gensim\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import multiprocessing\n",
    "import shutil\n",
    "import wget\n",
    "from zipfile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc2671fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'word2vec'\n",
    "#model = 'glove'\n",
    "language='he'\n",
    "dim=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b056edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'models' not in os.listdir('.'):\n",
    "    os.mkdir('./models/')\n",
    "if 'raws' not in os.listdir('./models/'):\n",
    "    os.mkdir('./models/raws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9a1f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(dim, language):\n",
    "    \"\"\"Training a Word2Vec model in Hebrew\"\"\"\n",
    "    inp = f'wiki.{language}.text'\n",
    "    outp = f'word2vec_{dim}_{language}.model'\n",
    "\n",
    "    if inp not in os.listdir('./corpora/'):\n",
    "        print('Corpus file not present, impossible to train')\n",
    "\n",
    "    if outp not in os.listdir('./models/raws/'):\n",
    "        print('Model file not present, starts training')\n",
    "        print(f'Training started {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "        model = gensim.models.word2vec.Word2Vec(LineSentence(f'./corpora/{inp}'), sg = 1, #1=SkipGram, 0=CBOW\n",
    "                                            size=dim, window=5, min_count=5, workers=multiprocessing.cpu_count())\n",
    "        # trim unneeded model memory = use (much) less RAM\n",
    "        model.init_sims(replace=True)\n",
    "\n",
    "        print(f'Training ended {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "        model.save(f'./models/raws/{outp}')\n",
    "    else:\n",
    "        print('Model file already present, no need to train')\n",
    "        \n",
    "def convert_word2vec_model_to_txt(dim, language):\n",
    "    \"\"\" For converting Word2Vec .model files to txt files containing the vectors in plain text.\"\"\"\n",
    "    inp = f'word2vec_{dim}_{language}.model'\n",
    "    print(f'Loading started {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    m = Word2Vec.load(f'./models/raws/{inp}')\n",
    "    print(f'Loading ended {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "    with open(f'./models/raws/word2vec_{dim}_{language}_vectors.txt', 'w') as f:\n",
    "        vocab = m.wv.vocab.keys()\n",
    "        model = m.wv\n",
    "        i = 0\n",
    "        for word in list(vocab):\n",
    "            vecs = model[word]\n",
    "            vecs = [str(v) for v in vecs]\n",
    "            i += 1\n",
    "            l = word+' '+' '.join(vecs)+'\\n'\n",
    "            f.write(l)\n",
    "    os.remove(f'./models/raws/word2vec_{dim}_{language}.model')\n",
    "    os.remove(f'./models/raws/word2vec_{dim}_{language}.model.wv.vectors.npy')\n",
    "    os.remove(f'./models/raws/word2vec_{dim}_{language}.model.trainables.syn1neg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e9aebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file already present, no need to train\n",
      "Loading started 2022-10-04 19:41:09\n",
      "Loading ended 2022-10-04 19:41:12\n"
     ]
    }
   ],
   "source": [
    "if model == 'word2vec':\n",
    "    train_word2vec(dim, language)\n",
    "    convert_word2vec_model_to_txt(dim, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90535bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_glove(dim, language):\n",
    "    if 'GloVe' not in os.listdir('./models/'):\n",
    "        URL = 'https://github.com/stanfordnlp/GloVe/archive/refs/heads/master.zip'\n",
    "        response = wget.download(URL, './models/master.zip')\n",
    "        with ZipFile('./models/master.zip', 'r') as zipObj:\n",
    "                zipObj.extractall('./models/')\n",
    "                #!unzip glove.42B.300d.zip\n",
    "        os.rename('./models/GloVe-master', './models/GloVe')\n",
    "        os.remove('./models/master.zip')\n",
    "                \n",
    "    inp = f'wiki.{language}.text'\n",
    "\n",
    "    shutil.copy('./models/GloVe/demo.sh', './models/GloVe/demo_backup.sh')\n",
    "\n",
    "    with open('./models/GloVe/demo.sh', 'r') as file :\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('CORPUS=text8', f'CORPUS=../../corpora/{inp}')\n",
    "    filedata = filedata.replace('VECTOR_SIZE=50', f'VECTOR_SIZE={dim}')\n",
    "\n",
    "    # Write the file out again\n",
    "    with open('./models/GloVe/demo.sh', 'w') as file:\n",
    "        file.write(filedata)\n",
    "\n",
    "    # note that this command will recreate the vocab file and the coocurrence matrix even if they already exist...\n",
    "    !cd ./models/GloVe/ && make && ./demo.sh\n",
    "\n",
    "    os.rename('./models/GloVe/demo_backup.sh', './models/GloVe/demo.sh')\n",
    "    os.rename('./models/GloVe/vectors.txt', f'./models/raws/glove_{dim}_{language}_vectors.txt')\n",
    "    os.remove('./models/GloVe/vectors.bin')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a176283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown"
     ]
    }
   ],
   "source": [
    "if model == 'glove':\n",
    "    train_glove(dim, language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c2757f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2c2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24192e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "495697db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e541d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
